{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10_test2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minicks/BigI/blob/master/cifar10_test2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hx8opwOY8v4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "\n",
        "cifar10 = keras.datasets.cifar10\n",
        "(X_train0, y_train0), (X_test0, y_test0) = cifar10.load_data()\n",
        "plt.figure(figsize=(20,10))\n",
        "for i in range(36):\n",
        "    plt.subplot(3,12,i+1)\n",
        "    plt.imshow(X_train0[i])\n",
        "    plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu7N2oTSZF9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "X_train = np.copy(X_train0).astype('float64')/255\n",
        "X_test = np.copy(X_test0).astype('float64')/255\n",
        "\n",
        "Y_train = to_categorical(y_train0, 10)\n",
        "Y_test = to_categorical(y_test0, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxCRIAFAZL7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa2QU1i_ZPDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout,BatchNormalization,Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# 신경망 생성\n",
        "model = Sequential()\n",
        "# 입력층 설정, 3 X 3 크기의 32개의 마스크 적용\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(32, 32,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "# 3 X 3 크기의 32개의 마스크 적용\n",
        "model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "# 맥스 풀링\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# # 3 X 3 크기의 64개의 마스크 적용\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "# # 3 X 3 크기의 64개의 마스크 적용\n",
        "model.add(Conv2D(64, (3, 3), activation='elu', padding='same'))\n",
        "# # 맥스 풀링\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# # 3 X 3 크기의 128개의 마스크 적용\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "# # 3 X 3 크기의 128개의 마스크 적용\n",
        "model.add(Conv2D(128, (3, 3), activation='elu', padding='same'))\n",
        "# # 맥스 풀링\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# # 2차원 배열 -> 1차원 배열\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "# # 1024 개의 노드를 가진 층(완전연결 층)\n",
        "model.add(Dense(1024, activation='elu'))\n",
        "model.add(BatchNormalization())\n",
        "# # 512 개의 노드를 가진 층(완전연결 층)\n",
        "model.add(Dense(512, activation='elu'))\n",
        "model.add(BatchNormalization())\n",
        "# # 출력층 생성\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(Conv2D(32, (5, 5), padding='same', input_shape=(32, 32, 3), kernel_initializer=\"glorot_uniform\"))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Activation('relu'))\n",
        "\n",
        "model1.add(Conv2D(32, (5, 5), padding='same', input_shape=(32, 32, 3), kernel_initializer=\"glorot_uniform\"))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(MaxPooling2D())\n",
        "\n",
        "model1.add(Conv2D(64, (5, 5), padding='same', kernel_initializer=\"glorot_uniform\"))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Activation('relu'))\n",
        "\n",
        "model1.add(Conv2D(64, (5, 5), padding='same', kernel_initializer=\"glorot_uniform\"))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(MaxPooling2D())\n",
        "\n",
        "\n",
        "model1.add(Conv2D(128, (5, 5), padding='same', kernel_initializer=\"glorot_uniform\"))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Activation('relu'))\n",
        "\n",
        "model1.add(Conv2D(128, (5, 5), padding='same', kernel_initializer=\"glorot_uniform\"))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(MaxPooling2D())\n",
        "\n",
        "# model1.add(Conv2D(240, (5, 5), padding='same', kernel_initializer=\"glorot_uniform\"))\n",
        "# model1.add(BatchNormalization())\n",
        "# model1.add(Activation('relu'))\n",
        "\n",
        "# model1.add(Conv2D(240, (5, 5), padding='same', kernel_initializer=\"glorot_uniform\"))\n",
        "# model1.add(BatchNormalization())\n",
        "# model1.add(Activation('relu'))\n",
        "# model1.add(MaxPooling2D())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(1024, activation=\"relu\"))\n",
        "model1.add(Dense(512, activation=\"relu\"))\n",
        "#model1.add(Dense(256, activation=\"relu\"))\n",
        "model1.add(Dense(128, activation=\"relu\"))\n",
        "model1.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "model1.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVT5hEhjZ8s3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.summary()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUzAeWiZaLrR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "7e313ea9-0410-4970-f304-f304f4017726"
      },
      "source": [
        "hist = model1.fit(X_train, Y_train, epochs=25, batch_size=450,\n",
        "                   validation_data=(X_test, Y_test), verbose=2)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/25\n",
            "50000/50000 - 12s - loss: 2.0257 - acc: 0.2641 - val_loss: 2.8935 - val_acc: 0.1170\n",
            "Epoch 2/25\n",
            "50000/50000 - 8s - loss: 1.4597 - acc: 0.4614 - val_loss: 2.1637 - val_acc: 0.2050\n",
            "Epoch 3/25\n",
            "50000/50000 - 7s - loss: 1.1662 - acc: 0.5787 - val_loss: 2.0803 - val_acc: 0.2445\n",
            "Epoch 4/25\n",
            "50000/50000 - 7s - loss: 0.9460 - acc: 0.6633 - val_loss: 1.3587 - val_acc: 0.5236\n",
            "Epoch 5/25\n",
            "50000/50000 - 7s - loss: 0.7970 - acc: 0.7186 - val_loss: 1.0474 - val_acc: 0.6400\n",
            "Epoch 6/25\n",
            "50000/50000 - 7s - loss: 0.6752 - acc: 0.7622 - val_loss: 0.9742 - val_acc: 0.6599\n",
            "Epoch 7/25\n",
            "50000/50000 - 7s - loss: 0.5776 - acc: 0.7964 - val_loss: 1.1356 - val_acc: 0.6219\n",
            "Epoch 8/25\n",
            "50000/50000 - 7s - loss: 0.5007 - acc: 0.8251 - val_loss: 0.8378 - val_acc: 0.7118\n",
            "Epoch 9/25\n",
            "50000/50000 - 7s - loss: 0.4315 - acc: 0.8492 - val_loss: 0.8193 - val_acc: 0.7323\n",
            "Epoch 10/25\n",
            "50000/50000 - 8s - loss: 0.3663 - acc: 0.8730 - val_loss: 1.5206 - val_acc: 0.6251\n",
            "Epoch 11/25\n",
            "50000/50000 - 8s - loss: 0.3149 - acc: 0.8892 - val_loss: 0.8864 - val_acc: 0.7403\n",
            "Epoch 12/25\n",
            "50000/50000 - 8s - loss: 0.2587 - acc: 0.9104 - val_loss: 1.2137 - val_acc: 0.6864\n",
            "Epoch 13/25\n",
            "50000/50000 - 8s - loss: 0.2353 - acc: 0.9161 - val_loss: 1.2088 - val_acc: 0.7043\n",
            "Epoch 14/25\n",
            "50000/50000 - 8s - loss: 0.1758 - acc: 0.9385 - val_loss: 1.0871 - val_acc: 0.7310\n",
            "Epoch 15/25\n",
            "50000/50000 - 8s - loss: 0.1509 - acc: 0.9468 - val_loss: 0.8532 - val_acc: 0.7817\n",
            "Epoch 16/25\n",
            "50000/50000 - 8s - loss: 0.1162 - acc: 0.9591 - val_loss: 1.0877 - val_acc: 0.7531\n",
            "Epoch 17/25\n",
            "50000/50000 - 8s - loss: 0.0998 - acc: 0.9643 - val_loss: 0.9468 - val_acc: 0.7721\n",
            "Epoch 18/25\n",
            "50000/50000 - 8s - loss: 0.0991 - acc: 0.9644 - val_loss: 1.0971 - val_acc: 0.7701\n",
            "Epoch 19/25\n",
            "50000/50000 - 8s - loss: 0.0730 - acc: 0.9746 - val_loss: 0.9809 - val_acc: 0.7951\n",
            "Epoch 20/25\n",
            "50000/50000 - 8s - loss: 0.0549 - acc: 0.9810 - val_loss: 1.0518 - val_acc: 0.7884\n",
            "Epoch 21/25\n",
            "50000/50000 - 8s - loss: 0.0582 - acc: 0.9793 - val_loss: 1.3743 - val_acc: 0.7509\n",
            "Epoch 22/25\n",
            "50000/50000 - 8s - loss: 0.0539 - acc: 0.9813 - val_loss: 1.3855 - val_acc: 0.7537\n",
            "Epoch 23/25\n",
            "50000/50000 - 8s - loss: 0.0743 - acc: 0.9743 - val_loss: 0.9971 - val_acc: 0.7880\n",
            "Epoch 24/25\n",
            "50000/50000 - 8s - loss: 0.0518 - acc: 0.9818 - val_loss: 1.3662 - val_acc: 0.7615\n",
            "Epoch 25/25\n",
            "50000/50000 - 8s - loss: 0.0575 - acc: 0.9798 - val_loss: 1.2120 - val_acc: 0.7751\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUVm7Awor2WE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "help(Conv2D)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}